Name,Etape,v3 partie 1,v3 partie 2
Coûts écologiques de l'Intelligence Artificielle,0-6. Extraction et consommation de ressources naturelles,"Les impacts environnementaux de l'IA ne cessent de croître. Ils varient selon la source d'électricité utilisée (nucléaire, charbon, renouvelables…). Il faut aussi prendre en compte l'extraction de métaux rares ou la consommation d'eau pour refroidir les centres de données. L'implantation de ces derniers artificialisent des sols et génèrent des îlots de chaleur. ","Estimée à 5% de l'empreinte écologique des centres de données, la part de l'IA devrait augmenter de 20 à 25% par an dans la prochaine décennie. Cette croissance s'explique par la multiplication des usages. Quand des millions de personnes utilisent ces systèmes quotidiennement, les coûts écologiques s'envolent."
Difficultés dans l'évaluation de l'impact écologique de l'IA,0-6. Extraction et consommation de ressources naturelles,"Il est difficile aujourd'hui d'évaluer précisément l'impact environnemental de l'IA, principalement du fait de l'opacité de des grandes entreprises du secteur qui partagent peu de données sur leur impact écologique. Les calculs sont néanmoins difficiles : comment déterminer ce qui relève ou non de l'IA dans l'impact écologique des centres de données ?","Les calculs sont complexes car les modèles d'IA sont très différents. Leur entrainement et leur usage peuvent être plus ou moins longs et consommateurs d'énergie. Ils peuvent utiliser des puces différentes. En plus, les centres de données utilisent des sources d'énergie plus ou moins polluantes."
Consommation en électricité et en eau des data centers,0-6. Extraction et consommation de ressources naturelles,L'entrainement et l'usage des modèles d'IA requiert des centres de données qui consomment de l'électricité pour alimenter leurs machines et de l'eau pour les refroidir. On estime qu'une requête ChatGPT utilise 10 fois plus d'électricité qu'un moteur de recherche classique. Une réponse ChatGPT d'une centaine de mots consommerait l'équivalent de 50cl d'eau. ,"L'AIE (Agence Internationale de l'Énergie) prévoit que la consommation électrique des centres de données doublera d'ici 2026. Des conflits d'usage de l'eau se créent localement. Aux Pays-Bas, un complexe Microsoft a consommé 4 fois plus d'eau que prévu en 2021 alors que les agriculteurs étaient soumis à restriction du fait de la sécheresse."
Extraction de ressources pour la production de semi-conducteurs,0-6. Extraction et consommation de ressources naturelles,"L’entrainement et l'utilisation des IA implique l’utilisation d’ordinateurs et de centres de données qui consomment des minerais semi-conducteurs. Leur extraction, leur transport et leur traitement nécessitent de grandes quantités d’énergie et d’eau. Cela émet aussi des produits chimiques toxiques et des gaz à effet de serre. ","Certains minerais utilisés dans le semi-conducteur sont abondants comme le silicium mais contrôlés par très peu d’acteurs. D’autres sont très rares comme le gallium, la Chine contrôle 98% de sa production et elle en interdit l’export depuis décembre 2024. 
"
Respect des droits d'auteur,1. Collecte de données d'entraînement,"Le droit d’auteur protège les créateurs d’utilisations non autorisées de leurs œuvres. L'industrie de l'IA utilise généralement des œuvres protégées en se basant sur un usage dit “loyal"". Cette exception au droit d’auteur permet d'utiliser des œuvres protégées pour la recherche si cela n'affecte pas beaucoup le marché du créateur. ","Aux Etats-Unis, le New York Times a porté plainte contre OpenAI, l'entreprise derrière ChatGPT, car elle aurait utilisé des millions d’articles protégés. Le New York Times affirme avoir perdu plusieurs milliards de dollars à cause de ChatGPT."
Biais dans les données d'entraînement,1. Collecte de données d'entraînement,Les ingénieurs construisent des réseaux de neurones et les entraînent avec des données qui doivent décrire l’état du monde ou d’un domaine. L’industrie de l’IA parle de “biais” pour désigner les problèmes dus à la sur ou sous représentation de certaines dimensions dans les données. ,"Par exemple, Common Crawl est un ensemble de données libre d’accès utilisé pour entraîner ChatGPT. Problème, il contient des milliards de pages web avec des contenus haineux, racistes ou sexistes. Ce type de contenu peut influencer les réponses du modèle."
Transparence et opacité des modèles,1. Collecte de données d'entraînement,"Il est difficile de comprendre les réponses d’un modèle d’IA sans savoir quelles données il utilise. Les entreprises gardent ces informations secrètes par crainte de procès liés au droit d’auteur et pour protéger leur ""secret"" de fabrication. Cette situation devrait changer avec le règlement européen sur l’IA qui oblige à publier la liste des données d’entraînement.","Avant, les entreprises donnaient cette information. Par exemple, la première version de ChatGPT utilisait 60 % de données issues de Common Crawl. Depuis la sortie de GPT4, OpenAI et la majorité des entreprises du secteur refusent de divulguer les données utilisées pour l'entrainement du modèle."
Epuisement des données disponibles pour l’IA,1. Collecte de données d'entraînement,"L’entraînement des modèles dépend de l’accès à des données de qualité, diversifiées et vérifiées. L’industrie de l’IA ferait face à un ""mur de données"", car elle aurait épuisé les données utilisables. Certaines entreprises utilisent des données “synthétiques” créées par une IA, mais cela peut réduire la qualité des résultats.","Un géant comme Google est avantagé dans cette course aux données avec des services comme Google Docs ou Youtube qui constituent une réserve de données d'entraînement. L'usage de données créées par des IA pose des problèmes de qualité et de fiabilité. Pour le journaliste Cory Doctorow, cela pourrait accentuer la dégradation (voire la ""merdification"") des contenus sur le web."
Découpage du texte en petites unités,2. Traitement des données,"Pour comprendre le langage, les modèles le traduisent en données numériques en découpant le texte en ""tokens"". Les ""tokens"" sont des unités de texte qui peuvent être plus petites qu'un mot. Cette approche est plus complexe pour des langues comme le chinois ou le japonais qui n'utilisent pas d'espaces entre les mots, doublant parfois le temps de traitement.","Un autre défi concerne le traitement des nombres : le modèle peut par exemple traiter ""380"" comme un seul token mais découper ""381"" en deux tokens (""38"" et ""1""). Cela perturbe la compréhension des relations mathématiques par le modèle. C'est l'une des raisons pour lesquelles les IA excellent en génération de texte mais peinent avec les calculs. Des alternatives comme les modèles MambaByte sont en cours de développement mais restent expérimentales."
Filtrage du contenu inapproprié,2. Traitement des données,"Les données d'entraînement des IA contiennent des informations erronées, des préjugés ou des incitations à la haine. Ces biais doivent être supprimés pour éviter leur reproduction par le modèle. L'industrie parle de ""dé-biaiser"" les données, supposant qu'il existe des données neutres et sans biais.","Pour Common Crawl, deux approches ont été utilisées : valoriser le contenu partagés dans certaines communautés en ligne comme Reddit, où les hommes sont surreprésentés. L'autre approche a consisté à filtrer automatiquement certains termes jugés inappropriés. Une base des données, la ""liste des mots sales et obscènes"", exclut du vocabulaire légitime des communautés LGBTQIA+."" Par exemple : ""homoerotic"" qui désigne une relation où une tension sexuelle est perceptible, sans qu'il y ait acte sexuel."
Normalisation des données,2. Traitement des données,La normalisation standardise le texte pour le rendre plus facilement traitable par la machine lors de l'entraînement du modèle. Cette étape réduit la complexité et améliore les performances des systèmes d'IA. Mais elle peut aussi enlever des informations importantes comme le genre des mots. ,"Une première technique consiste à supprimer les accents et les majuscules ou à corriger les erreurs orthographiques. Une autre technique, dite de “lemmatisation”, consiste à regrouper les variantes d'un mot (par exemple : ""connecter"", ""connecté"", ""connexion""). Cette étape améliore les performances des systèmes d'IA. Mais elle peut aussi enlever des informations importantes comme le genre des mots. Par exemple, en anglais, le mot ""doctor"" sera traduit par défaut par ""un médecin"" et ""nurse"" par ""une infirmière""."
Ajout de diversité linguistique,2. Traitement des données,"Les données d'entraînement des IA manquent de diversité linguistique du web et sur-valorisent l'anglais. En conséquence, les modèles d'IA intègrent une vision du monde anglo-américaine et sont moins performants pour les 4 milliards de personnes ne parlant pas une des dix principales langues dans le monde.","Dans Common Crawl, base de référence pour l'entraînement des IA, l'anglais représente 43% des pages, le français 4%, et le wolof seulement 0,002% (bien que ce soit la langue la plus parlée au Sénégal). Les ingénieurs utilisent souvent des versions réduites de Common Crawl contenant uniquement des textes en anglais. "
Comparaison des résultats avec des données de validation et de test,3. Entrainement du modèle,"Pour vérifier si un modèle d'IA fonctionne bien, on teste sa capacité à généraliser sur de nouvelles données. Comme un élève qui passe des examens, le modèle est évalué dans sa capacité à s'adapter aux exigences des humains. Le modèle est alors ajusté pour produire des résultats adaptés aux tests.","Pour cela, on divise les données en trois groupes : apprentissage (pour entraîner), validation (pour vérifier les progrès) et test (pour l'évaluation finale). Ces dernières données n'ont jamais été vues par le modèle pour vérifier l'amélioration des résultats."
Lecture attentive du texte par la machine,3. Entrainement du modèle,"Depuis 2017, l'analyse de texte par l'IA a profondément changé avec le système ""transformer"". Les anciens systèmes analysaient les mots isolément, sans comprendre leurs liens ni le sens global des phrases. Désormais, le modèle prend en compte le contexte de chaque mot et peut suivre le rôle des mots dans les phrases. ","Par exemple, dans ""le chat a poursuivi le rat, puis il l'a mangé"", la machine comprend que ""il"" fait référence au chat grâce au contexte."
Regroupement des mots similaires entre eux,3. Entrainement du modèle,"Pour comprendre le sens des mots, l'IA les place dans un espace qui est une représentation mathématique du langage. Dans cet espace, les mots de sens proche sont positionnés les uns près des autres. L'IA calcule ces positions en analysant quels mots apparaissent souvent ensemble dans les textes.","Par exemple, “maison” et “habitation” seront proches car ils veulent dire la même chose. Un mot peut avoir plusieurs sens et donc être proche de différents groupes : “charme” sera proche de “séduction” mais aussi de “magie”. "
Entrainement d'un réseau de neurones artificiels,3. Entrainement du modèle,"Un réseau de neurones est un système inspiré du cerveau humain. On parle de ""neurones"" car, comme dans le cerveau, chaque unité reçoit des informations, les traite, et les transmet aux suivantes. Les ""neurones"" sont organisés en couches successives de la réception des données, à leur traitement jusqu'à la production du résultat.","Un algorithme indique au réseau si le résultat est juste afin qu'il puisse ajuster un paramètre dans les neurones. Cet apprentissage se fait en répétant l'opération des milliers de fois sur de très grands volumes de données, jusqu'à ce que le réseau produise des résultats satisfaisants."""
Renforcement des résultats du modèle par des humains,4. Renforcement du modèle,"Les humains améliorent les modèles d'IA en vérifiant leurs résultats. Par exemple, ils s'assurent qu'un texte généré est clair et sans erreurs. Les ingénieurs utilisent un système de récompenses : si le texte est correct, le modèle reçoit un bonus, sinon, un malus. Le modèle adapte alors ses réponses aux attentes des humains. ","Ce travail d’annotation et d’évaluation est bien souvent externalisé en Afrique (au Kenya pour le cas de ChatGPT) ou par des réfugiés obligés de travailler dans des conditions de travail indignes. Les usagers des IA génératives contribuent à ce travail de ""renforcement"" en signaler si la réponse est satisfaisante (souvent avec un 👍 ou un 👎). "
Mesure et comparaison des performances du modèle,4. Renforcement du modèle,"Les modèles d'IA sont évalués avec des mesures de performance. On compile ces scores dans des tableaux de classement (appelés “benchmarks”) pour voir quels modèles sont les meilleurs pour une tâche précise (classification de texte, exactitude des résultats…). ","Ces mesures posent problème. Il apparaît évident que les modèles sont artificiellement optimisés pour réussir certains tâches comme le test d'admission à l'université aux Etats-Unis (le ""SAT""). Ces mesures sont généralement réalisées sur des textes en anglais. On manque de données sur la performance des modèles dans d'autres langues dont le français. "
Ajustement de modèles pré-entrainés,4. Renforcement du modèle,"Il est difficile de créer des modèles d'IA très performants à partir de zéro. Cela demande beaucoup de puissance de calcul et de grandes quantités de données. Pour faciliter cela, les informaticiens utilisent souvent des modèles déjà entraînés sur des faits scientifiques, ou sur des de vaste corpus issus du web. ","Ils peuvent alors travailler avec moins de données sur ces modèles pré-entraînés, ce qui les aide à obtenir de bons résultats sans avoir à repartir de zéro. Par exemple, pour la classification de textes en français, on peut citer le modèle pré-entrainé CamemBERT. De grands modèles sont aussi partagés librement par des entreprises comme Meta, Mistral ou Deepseek."
Micro-tâches et travail du clic,4. Renforcement du modèle,"La création et la maintenance des services basés sur l'IA nécessitent beaucoup de travail humain, particulièrement pour l'annotation des données : lorsque les textes sont décrits et caractérisés manuellement. Pour réduire les coûts, les entreprises font souvent appel à des sous-traitants qui imposent de mauvaises conditions de travail.","Par exemple, à Madagascar, des étiqueteurs de données reçoivent des conversations client non triées et doivent identifier le ton émotionnel (positif, négatif, neutre) pour entraîner des modèles de traitement du langage naturel. "
Confidentialité des échanges avec l'agent conversationnel,5. Usage du modèle,"Utiliser une IA Générative de texte dans son travail ou sa vie personnelle est susceptible de communiquer des informations confidentielles à des tiers. Puisque nos données personnelles servent à l'entraînement du modèle, un usager malin pourrait les générer à partir d’une requête. ",Ce problème de confidentialité a conduit l’Italie à interdire temporairement ChatGPT pour non-respect du RGPD.   
Invention d'informations,5. Usage du modèle,"Les grands modèles de langage (LLM) sont des systèmes d'IA programmés pour donner systématiquement une réponse, synthétiser des informations et prédire la suite la plus probable d'un texte. Ces modèles produisent des réponses qui semblent plausibles car elles correspondent aux motifs statistiques du langage, mais qui peuvent être factuellement fausses. ","Le terme ""hallucination"" est controversé car il suggère que l'IA aurait une conscience ou des perceptions altérées, alors qu'il s'agit d'erreurs statistiques de prédiction. Par exemple, la chercheuse en éthique Margaret Mitchell a demandé à Gemini (Google) ""combien de présidents musulmans avaient eu les Etats-Unis ?"" Gemini a répondu un, citant Barack Obama qui est chrétien protestant."
Consommation d'électricité à chaque usage de l'agent,5. Usage du modèle,"Plus une IA est utilisée, plus elle consomme d'électricité et son impact sur l'environnement augmente. Les calculs faits pendant son utilisation sont très gourmands en énergie. Microsoft a signé en 2024 un contrat pour relancer la centrale nucléaire de Three Mile Island, arrêtée pour des raisons économiques.","Pour réduire cette consommation, on peut faire fonctionner les calculs d'IA directement sur les appareils des utilisateurs, comme les smartphones ou les drones, ou sur des serveurs locaux, comme ceux des hôpitaux. Les gains d'efficacité énergétique sont souvent annulés par l'augmentation massive des usages (""effet rebond""). "
Omniprésence de l'IA dans les usages numériques,5. Usage du modèle,"L'IA est partout dans nos vies numériques. Elle se trouve dans les filtres anti-spam, les suggestions de phrases dans nos e-mails, les assistants vocaux et les recommandations de contenus sur les plateformes. L'utilisation de l'IA générative va augmenter, car elle sera intégrée aux moteurs de recherche et aux systèmes d'exploitation. ","Nous ne connaissons pas toujours toutes les applications de l'IA, et parfois, son utilisation nous est imposée sans que nous en soyons conscients."